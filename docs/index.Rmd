---
title: 'R : Sample Size and Power Calculations for Tests Comparing Proportions in Clinical Research'
author: "John Pauline Pineda"
date: "May 21, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```

# **1. Table of Contents**
|
| This document presents a non-exhaustive list of sample size and power calculations for clinical research proportion comparison tests using various helpful packages in <mark style="background-color: #CCECFF">**R**</mark>.
|
| Proportion comparison tests applied during clinical research refer to trials evaluated in terms of discrete clinical endpoints. The objectives of the intended clinical trials usually include the evaluation of clinical response (including complete response, partial response, and stable disease), survival in cancer trials, and the presence of adverse events in clinical trials. The equations applied in this study (mostly contained from the book  <mark style="background-color: #CCECFF">**Sample Size Calculations in Clinical Research**</mark> and implemented using the <mark style="background-color: #CCECFF">**base**</mark> package) attempt to provide calculations for the sample size and statistical power based on the study objectives and hypotheses of interest. 
|
##  1.1 One-Sample Design (OSD)
|
| [One-Sample Design](https://www.taylorfrancis.com/books/mono/10.1201/9781315183084/sample-size-calculations-clinical-research-shein-chung-chow-jun-shao-hansheng-wang-yuliya-lokhnygina) involves individual binary response classes from sampled subjects. In clinical research, classes could be the binary indicator of the responsiveness to the intervention applied within a treatment group. Responses are assumed to be independent and identically distributed normal random variables with proportion equal to the true response rate. Parameters needed for the computations are as follows:
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : True response rate obtained from sampled subjects 
|
| **[B]** <span style="color: #FF0000">Reference</span> : Baseline value for comparison
|
| **[C]** <span style="color: #FF0000">Alpha</span> : Maximum allowed Type I error
|
| **[D]** <span style="color: #FF0000">Beta</span> : Maximum allowed Type II error
|
| **[E]** <span style="color: #FF0000">Delta</span> : 
|      **[E.1]** Minimum testing margin to establish that the true response rate is much better than reference
|      **[E.2]** Minimum testing margin to establish that the true response rate is not much worse as the reference
|      **[E.3]** Minimum testing margin to establish that the true response rate is no better and no worse than the reference
|
| A case scenario was provided as follows to demonstrate sample size computation and power analysis as applied on different types of hypotheses:
|
| **[Case Scenario]** A clinical research study is being pursued concerning osteoporosis in post-menopausal women. Osteoporosis and osteopenia (or decreased bone mass) most commonly develop in post-menopausal women. The consequences of osteoporosis are vertebral crush fractures and hip fractures. It is of interest to evaluate the treatment effect in terms of the response rate at the end of the study. A subject may be defined as a responder if there is an improvement in bone density by more than one standard deviation (SD) or 30% of the measurements of bone density.
|
###  1.1.1 Test for Equality (OSD_EQUALITY)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For prevention of progression from osteopenia to osteoporosis, the study aims to demonstrate that the true response rate post-treatment and a reference rate of 15% are different. Given a level of significance of 0.05, evaluate the sample size range for a test of equality to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Post-treatment true response rate - Reference response rate equals 0
|
| **[Alternative Hypothesis]** Post-treatment mean bone density - Reference response rate does not equal 0
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies difference between the true response rate post-treatment and reference rate
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : 0 testing margin for the Test of Equality hypothesis
|
```{r section_1.1.1, warning=FALSE, message=FALSE}

##################################
# Loading R libraries
##################################
library(moments)
library(car)
library(multcomp)
library(effects)
library(psych)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(rstatix)
library(ggfortify)
library(trend)

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha/2)+qnorm(1-beta_1))/(p_ResponseRate-p_Reference))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha/2))+pnorm(-z_Beta30-qnorm(1-alpha/2)))

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha/2)+qnorm(1-beta_2))/(p_ResponseRate-p_Reference))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha/2))+pnorm(-z_Beta20-qnorm(1-alpha/2)))

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha/2)+qnorm(1-beta_3))/(p_ResponseRate-p_Reference))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha/2))+pnorm(-z_Beta10-qnorm(1-alpha/2)))

OneSampleDesign.Equality <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.Equality) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.Equality.Reshaped <- gather(OneSampleDesign.Equality,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.Equality.Reshaped$Label <- rep("OSD_EQUALITY",nrow(OneSampleDesign.Equality.Reshaped))

OneSampleDesign.Equality.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.Equality.PowerAnalysis <- ggplot(OneSampleDesign.Equality.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Equality"))

```

###  1.1.2 Test for Non-Inferiority (OSD_NONINFERIORITY)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For prevention of progression from osteopenia to osteoporosis, the study aims to demonstrate that the true response rate post-treatment is not much worse than the reference rate of 15% by a clinically meaningful difference equal to −5%. Given a level of significance of 0.05, evaluate the sample size range for a test of non-inferiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Post-treatment true response rate - Reference response rate <= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Post-treatment mean bone density - Reference response rate > Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies non-inferiority of the true response rate post-treatment as compared to the reference rate, given the delta
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : -5% testing margin for the Test of Non-Inferiority hypothesis
|
```{r section_1.1.2, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the non-inferiority delta
##################################
delta=-0.05

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_1))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_2))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_3))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))

OneSampleDesign.NonInferiority <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.NonInferiority) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.NonInferiority.Reshaped <- gather(OneSampleDesign.NonInferiority,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.NonInferiority.Reshaped$Label <- rep("OSD_NONINFERIORITY",nrow(OneSampleDesign.NonInferiority.Reshaped))

OneSampleDesign.NonInferiority.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.NonInferiority.PowerAnalysis <- ggplot(OneSampleDesign.NonInferiority.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Non-Inferiority"))

```

###  1.1.3 Test for Superiority (OSD_SUPERIORITY)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For prevention of progression from osteopenia to osteoporosis, the study aims to demonstrate that the true response rate post-treatment is much better than the reference rate of 15% by a clinically meaningful difference equal to +20%. Given a level of significance of 0.05, evaluate the sample size range for a test of superiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Post-treatment true response rate - Reference response rate <= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Post-treatment mean bone density - Reference response rate > Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies superiority of the true response rate post-treatment as compared to the reference rate, given the delta
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : +20% testing margin for the Test of Superiority hypothesis
|
```{r section_1.1.3, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the Superiority delta
##################################
delta=0.05

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_1))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_2))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_3))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))

OneSampleDesign.Superiority <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.Superiority) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.Superiority.Reshaped <- gather(OneSampleDesign.Superiority,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.Superiority.Reshaped$Label <- rep("OSD_SUPERIORITY",nrow(OneSampleDesign.Superiority.Reshaped))

OneSampleDesign.Superiority.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.Superiority.PowerAnalysis <- ggplot(OneSampleDesign.Superiority.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Superiority"))

```

###  1.1.4 Test for Equivalence (OSD_EQUIVALENCE)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For a special investigation, the study aims to demonstrate that the true response rate post-treatment is not much worse or better than the reference rate of 15% by a clinically meaningful difference equal to 10%. Given a level of significance of 0.05, evaluate the sample size range for a test of superiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Absolute value of (Post-treatment true response rate - Reference response rate) >= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Absolute value of (Post-treatment true response rate - Reference response rate) < Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies equivalence of the true response rate post-treatment as compared to the reference rate, given the delta
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : +10% testing margin for the Test of Equivalence hypothesis
|
```{r section_1.1.4, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the Equivalence delta
##################################
delta=0.05

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_1/2))/(abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta30)
z_Beta30=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=2*(pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))-1)

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_2/2))/(abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta20)
z_Beta20=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=2*(pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))-1)

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_3/2))/(abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta10)
z_Beta10=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=2*(pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))-1)

OneSampleDesign.Equivalence <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.Equivalence) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.Equivalence.Reshaped <- gather(OneSampleDesign.Equivalence,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.Equivalence.Reshaped$Label <- rep("OSD_EQUIVALENCE",nrow(OneSampleDesign.Equivalence.Reshaped))

OneSampleDesign.Equivalence.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.Equivalence.PowerAnalysis <- ggplot(OneSampleDesign.Equivalence.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Equivalence"))

```

###  1.1.5 Evaluation Summary
|
| Sample computation and power analysis comparison:
|
| **[A]** The minimum sample size required for the treatment group in a One-Sample Design study is dependent upon the following factors defined and hypothesized prior to the clinical research:
|      **[A.1]** Study Hypothesis (Equality, Non-Inferiority, Superiority, Equivalence)
|      **[A.2]** Level of significance (Alpha) : Lower value increases sample size
|      **[A.3]** Power of the test (Beta) : Higher value increases sample size
|      **[A.5]** Epsilon (Difference between True Response Rate and Reference Rate) : Lower value increases sample size
|      **[A.6]** Delta (Testing margin, as applicable) : Higher value increases sample size
| **[B]** Given the level of significance = 5%, reference rate = 15% and true response rate after treatment = 40% to 60% representing epsilon values = 25% to 45%, the range of sample sizes is given on the respective power analyses provided for each study hypotheses -
|      **[B.1]** OSD_EQUALITY : 
|             **[B.1.1]** For 70% power, sample size = 8 to 24 
|             **[B.1.2]** For 80% power, sample size = 10 to 31 
|             **[B.1.3]** For 90% power, sample size = 13 to 41 
|      **[B.2]** OSD_NONINFERIORITY with Delta = -5% : 
|             **[B.2.1]** For 70% power, sample size = 5 to 13 
|             **[B.2.2]** For 80% power, sample size = 6 to 17 
|             **[B.2.3]** For 90% power, sample size = 9 to 23 
|      **[B.3]** OSD_SUPERIORITY with Delta = +20% :  
|             **[B.3.1]** For 70% power, sample size = 8 to 29 
|             **[B.3.2]** For 80% power, sample size = 10 to 38 
|             **[B.3.3]** For 90% power, sample size = 13 to 52 
|      **[B.4]** OSD_EQUIVALENCE with Delta = +10% : 
|             **[B.4.1]** For 70% power, sample size = 11 to 44 
|             **[B.4.2]** For 80% power, sample size = 13 to 52 
|             **[B.4.3]** For 90% power, sample size = 17 to 65 
|
```{r section_1.1.5, warning=FALSE, message=FALSE}
##################################
# Consolidating the power analyses charts
##################################

OSD_EQUALITY.PowerAnalysis <- ggplot(OneSampleDesign.Equality.Reshaped,
                                     aes(x=Posttreatment.True.Response.Rate,
                                         y=Sample.Size,
                                         color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) 

OSD_NONINFERIORITY.PowerAnalysis <- ggplot(OneSampleDesign.NonInferiority.Reshaped,
                                           aes(x=Posttreatment.True.Response.Rate,
                                               y=Sample.Size, 
                                               color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

OSD_SUPERIORITY.PowerAnalysis <- ggplot(OneSampleDesign.Superiority.Reshaped,
                                        aes(x=Posttreatment.True.Response.Rate,
                                            y=Sample.Size, 
                                            color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

OSD_EQUIVALENCE.PowerAnalysis <- ggplot(OneSampleDesign.Equivalence.Reshaped,
                                        aes(x=Posttreatment.True.Response.Rate,
                                            y=Sample.Size,
                                            color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))


OSD_PowerAnalysis <- ggarrange(OSD_EQUALITY.PowerAnalysis,
                               OSD_NONINFERIORITY.PowerAnalysis,
                               OSD_SUPERIORITY.PowerAnalysis,
                               OSD_EQUIVALENCE.PowerAnalysis,
                               ncol=2, nrow=2)

annotate_figure(OSD_PowerAnalysis,
                top = text_grob("One-Sample Design Power Analysis by Statistical Hypothesis",
                                color = "black",
                                face = "bold",
                                size = 14))

```

|
##  1.2 Two-Sample Unpaired Design (TSUD)
|
| [Two-Sample Unpaired Design](https://www.taylorfrancis.com/books/mono/10.1201/9781315183084/sample-size-calculations-clinical-research-shein-chung-chow-jun-shao-hansheng-wang-yuliya-lokhnygina) involves individual proportions from sampled subjects between treatment and control groups. In clinical research, responses could be between a test drug and a placebo control, or an active agent. Responses are assumed to be independent and identically distributed normal random variables with proportion equal to the true response rate for each group. Parameters needed for the computations are as follows:
|
| **[A]** <span style="color: #FF0000">Treatment Response Rate</span> : Response rate obtained from sampled subjects in the treatment group
|
| **[B]** <span style="color: #FF0000">Control Response Rate</span> : Response rate obtained from sampled subjects in the control group
|
| **[C]** <span style="color: #FF0000">Epsilon</span> : Response rate differences between the treatment and control groups
|
| **[D]** <span style="color: #FF0000">Alpha</span> : Maximum allowed Type I error
|
| **[E]** <span style="color: #FF0000">Beta</span> : Maximum allowed Type II error
|
| **[F]** <span style="color: #FF0000">Kappa</span> : Matching ratio between the Treatment and Control groups
|
| **[G]** <span style="color: #FF0000">Delta</span> : 
|      **[G.1]** Minimum testing margin to establish that the treatment response rate is much better than control
|      **[G.2]** Minimum testing margin to establish that the treatment response rate is much better than control
|      **[G.3]** Minimum testing margin to establish that the treatment response rate is much better than control
|
| A case scenario was provided as follows to demonstrate sample size computation and power analysis as applied on different types of hypotheses:
|
| **[Case Scenario]** A clinical research study is being pursued concerning the evaluation of anti-infective agents in the treatment of patients with skin and skin structure infections. As it is well known, gram-positive and gram-negative pathogens are commonly associated with skin and skin structure infections such as streptococci, staphylococci, and various strains of enterobacteriaceae. For the evaluation of the effectiveness of a test antibiotic agent, clinical assessments and cultures are usually done at a post-treatment visits (e.g., between 4 and 8 days) after treatment has been completed but prior to treatment with another anti-microbial agent. If the culture is positive, the pathogen(s) is usually identified and susceptibility testingis performed. The effectiveness of therapy is usually assessed based on clinical and bacteriological responses at post-treatment visit. For example, clinical responses may include cure (e.g., no signs of skin infection at post-treatment visits), improvment (e.g., the skin infection has resolved to the extent that no further systemic antibiotic therapy is needed based on the best judgment of the investigator), failure (e.g., lack of significant improvement in the signs and symptoms of the skin infection at or before post-treatment visits such that a change in antibiotic treatment is required). On the other hand, bacteriological responses may include cure (e.g., all pathogens eradicated at post-treatment day 4-8 or material suitable for culturinghas diminished to a degree that proper cultures cannot be obtained), colonization (e.g., isolation of pathogen(s) from the original site of infection in the absence of local or systemic signs of infection at post-treatment visits), and failure (e.g., any pathogen(s) isolated at post-treatment visits coupled with the investigator’s decision to prescribe alternate antibiotic therapy). Suppose that a pharmaceutical company is interested in conducting a clinical trial to compare the efficacy, safety, and tolerability of two antimicrobial agents when administered orally once daily in the treatment of patients with skin and skin structure infections.
|
###  1.2.1 Test for Equality (TSUD_EQUALITY)
|
| **[Research Question]** Suppose that a difference of 20 to 30% in clinical response of cure is considered of clinically meaningful difference between the two compared anti-microbial agents. The study aims to demonstrate that the response rate change between the new anti-microbial agent and active control agent with true cure rate of 65% are different. Given a level of significance of 0.05 and matching ratio between both groups equal to 1, evaluate the sample size range for a test of equality to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Cure rate of the new anti-microbial agent - Cure rate of the active control agent equals 0
|
| **[Alternative Hypothesis]** Cure rate of the new anti-microbial agent - Cure rate of the active control agent does not equal 0
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies difference between the cure rate between both anti-microbial agents
|
| **[A]** <span style="color: #FF0000">Epsilon</span> : 20 to 30% at 2% intervals
|      **[A.1]** <span style="color: #FF0000">Control Response Rate</span> : 65%
|      **[A.2]** <span style="color: #FF0000">Treatment Response Rate</span> : 85% to 95% at 2% intervals
|
| **[B]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[C]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[D]** <span style="color: #FF0000">Kappa</span> : 1.0
|
| **[E]** <span style="color: #FF0000">Delta</span> : 0 testing margin for the Test of Equality hypothesis
|
```{r section_1.2.1, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for epsilon
##################################
epsilon=seq(0.20,0.30,0.02)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.65

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
(p_ResponseRate=p_Reference + epsilon)

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining a fixed hypothesized value for kappa
##################################
kappa=1.0

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha/2)+qnorm(1-beta_1))/
                                      (p_ResponseRate-p_Reference))^2)

ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30/kappa+p_Reference
       *(1-p_Reference)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha/2))+pnorm(-z_Beta30-qnorm(1-alpha/2)))

beta_2=beta[2]
(n_Beta20=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha/2)+qnorm(1-beta_2))/
                                      (p_ResponseRate-p_Reference))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20/kappa+p_Reference
       *(1-p_Reference)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha/2))+pnorm(-z_Beta20-qnorm(1-alpha/2)))

beta_3=beta[3]
(n_Beta10=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha/2)+qnorm(1-beta_3))/
                                      (p_ResponseRate-p_Reference))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10/kappa+p_Reference
       *(1-p_Reference)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha/2))+pnorm(-z_Beta10-qnorm(1-alpha/2)))

TwoSampleUnpairedDesign.Equality <- as.data.frame(cbind(epsilon,n_Beta30,n_Beta20,n_Beta10))
names(TwoSampleUnpairedDesign.Equality) <- c("Cure.Rate.Change",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
TwoSampleUnpairedDesign.Equality.Reshaped <- gather(TwoSampleUnpairedDesign.Equality,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
TwoSampleUnpairedDesign.Equality.Reshaped$Label <- rep("TSUD_EQUALITY",nrow(TwoSampleUnpairedDesign.Equality.Reshaped))

TwoSampleUnpairedDesign.Equality.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(TwoSampleUnpairedDesign.Equality.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.Equality.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("Two-Sample Unpaired Design : Test for Equality"))

```

###  1.2.2 Test for Non-Inferiority (TSUD_NONINFERIORITY)
|
| **[Research Question]** Suppose that a difference of 20 to 30% in clinical response of cure is considered of clinically meaningful difference between the two compared anti-microbial agents. The study aims to demonstrate that the response rate change for the new anti-microbial agent is not much worse than active control agent with true cure rate of 65% by a clinically meaningful difference equal to -10%. Given a level of significance of 0.05 and matching ratio between both groups equal to 1, evaluate the sample size range for a test of non-inferiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Cure rate of the new anti-microbial agent - Cure rate of the active control agent <= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Cure rate of the new anti-microbial agent - Cure rate of the active control agent > Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies non-inferiority between the cure rate between both anti-microbial agents, given the delta
|
| **[A]** <span style="color: #FF0000">Epsilon</span> : 20 to 30% at 2% intervals
|      **[A.1]** <span style="color: #FF0000">Control Response Rate</span> : 65%
|      **[A.2]** <span style="color: #FF0000">Treatment Response Rate</span> : 85% to 95% at 2% intervals
|
| **[B]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[C]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[D]** <span style="color: #FF0000">Kappa</span> : 1.0
|
| **[E]** <span style="color: #FF0000">Delta</span> : -10% testing margin for the Test of Non-Inferiority hypothesis
|
```{r section_1.2.2, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for epsilon
##################################
epsilon=seq(0.20,0.30,0.02)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.65

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
(p_ResponseRate=p_Reference + epsilon)

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the non-inferiority delta
##################################
delta=-0.10

##################################
# Defining a fixed hypothesized value for kappa
##################################
kappa=1.0

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_1))/
                                      (p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30/kappa+p_Reference
       *(1-p_Reference)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))

beta_2=beta[2]
(n_Beta20=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_2))/
                                      (p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20/kappa+p_Reference
       *(1-p_Reference)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))

beta_3=beta[3]
(n_Beta10=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_3))/
                                      (p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10/kappa+p_Reference
       *(1-p_Reference)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))

TwoSampleUnpairedDesign.NonInferiority <- as.data.frame(cbind(epsilon,n_Beta30,n_Beta20,n_Beta10))
names(TwoSampleUnpairedDesign.NonInferiority) <- c("Cure.Rate.Change",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
TwoSampleUnpairedDesign.NonInferiority.Reshaped <- gather(TwoSampleUnpairedDesign.NonInferiority,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
TwoSampleUnpairedDesign.NonInferiority.Reshaped$Label <- rep("TSUD_NONINFERIORITY",nrow(TwoSampleUnpairedDesign.NonInferiority.Reshaped))

TwoSampleUnpairedDesign.NonInferiority.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(TwoSampleUnpairedDesign.NonInferiority.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.NonInferiority.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("Two-Sample Unpaired Design : Test for NonInferiority"))

```

###  1.2.3 Test for Superiority (TSUD_SUPERIORITY)
|
| **[Research Question]** Suppose that a difference of 20 to 30% in clinical response of cure is considered of clinically meaningful difference between the two compared anti-microbial agents. The study aims to demonstrate that the response rate change for the new anti-microbial agent is much better than active control agent with true cure rate of 65% by a clinically meaningful difference equal to +2%. Given a level of significance of 0.05 and matching ratio between both groups equal to 1, evaluate the sample size range for a test of non-inferiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Cure rate of the new anti-microbial agent - Cure rate of the active control agent <= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Cure rate of the new anti-microbial agent - Cure rate of the active control agent > Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies non-inferiority between the cure rate between both anti-microbial agents, given the delta
|
| **[A]** <span style="color: #FF0000">Epsilon</span> : 20 to 30% at 2% intervals
|      **[A.1]** <span style="color: #FF0000">Control Response Rate</span> : 65%
|      **[A.2]** <span style="color: #FF0000">Treatment Response Rate</span> : 85% to 95% at 2% intervals
|
| **[B]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[C]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[D]** <span style="color: #FF0000">Kappa</span> : 1.0
|
| **[E]** <span style="color: #FF0000">Delta</span> : +2% testing margin for the Test of Superiority hypothesis
|
```{r section_1.2.3, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for epsilon
##################################
epsilon=seq(0.20,0.30,0.02)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.65

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
(p_ResponseRate=p_Reference + epsilon)

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the non-inferiority delta
##################################
delta= 0.02

##################################
# Defining a fixed hypothesized value for kappa
##################################
kappa=1.0

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_1))/
                                      (p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30/kappa+p_Reference
       *(1-p_Reference)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))

beta_2=beta[2]
(n_Beta20=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_2))/
                                      (p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20/kappa+p_Reference
       *(1-p_Reference)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))

beta_3=beta[3]
(n_Beta10=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_3))/
                                      (p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10/kappa+p_Reference
       *(1-p_Reference)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))

TwoSampleUnpairedDesign.Superiority <- as.data.frame(cbind(epsilon,n_Beta30,n_Beta20,n_Beta10))
names(TwoSampleUnpairedDesign.Superiority) <- c("Cure.Rate.Change",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
TwoSampleUnpairedDesign.Superiority.Reshaped <- gather(TwoSampleUnpairedDesign.Superiority,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
TwoSampleUnpairedDesign.Superiority.Reshaped$Label <- rep("TSUD_SUPERIORITY",nrow(TwoSampleUnpairedDesign.Superiority.Reshaped))

TwoSampleUnpairedDesign.Superiority.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(TwoSampleUnpairedDesign.Superiority.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.Superiority.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("Two-Sample Unpaired Design : Test for Superiority"))

```

###  1.2.4 Test for Equivalence (TSUD_EQUIVALENCE)
|
| **[Research Question]** Suppose that a difference of 20 to 30% in clinical response of cure is considered of clinically meaningful difference between the two compared anti-microbial agents. The study aims to demonstrate that the response rate change for the new anti-microbial agent is not much worse or better than active control agent with true cure rate of 65% by a clinically meaningful difference equal to +0.5%. Given a level of significance of 0.05 and matching ratio between both groups equal to 1, evaluate the sample size range for a test of non-inferiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Absolute value of (Cure rate of the new anti-microbial agent - Cure rate of the active control agent) >= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Absolute value of (Cure rate of the new anti-microbial agent - Cure rate of the active control agent) < Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies non-inferiority between the cure rate between both anti-microbial agents, given the delta
|
| **[A]** <span style="color: #FF0000">Epsilon</span> : 20 to 30% at 2% intervals
|      **[A.1]** <span style="color: #FF0000">Control Response Rate</span> : 65%
|      **[A.2]** <span style="color: #FF0000">Treatment Response Rate</span> : 85% to 95% at 2% intervals
|
| **[B]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[C]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[D]** <span style="color: #FF0000">Kappa</span> : 1.0
|
| **[E]** <span style="color: #FF0000">Delta</span> : +1% testing margin for the Test of Equivalence hypothesis
|
```{r section_1.2.4, warning=FALSE, message=FALSE}
##################################
# Defining a range of possible hypothesized values for epsilon
##################################
epsilon=seq(0.20,0.30,0.02)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.65

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
(p_ResponseRate=p_Reference + epsilon)

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the non-inferiority delta
##################################
delta= 0.02

##################################
# Defining a fixed hypothesized value for kappa
##################################
kappa=1.0

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_1/2))/
                                      (abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta30)
z_Beta30=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30/kappa+p_Reference
       *(1-p_Reference)/n_Beta30)
(Power_Beta30=2*(pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))-1)

beta_2=beta[2]
(n_Beta20=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_2/2))/
                                      (abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta20)
z_Beta20=(abs(p_ResponseRate-p_Reference)-p_Reference-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20/kappa+p_Reference
       *(1-p_Reference)/n_Beta20)
(Power_Beta20=2*(pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))-1)

beta_3=beta[3]
(n_Beta10=(p_ResponseRate*(1-p_ResponseRate)/kappa+p_Reference*
             (1-p_Reference))*((qnorm(1-alpha)+qnorm(1-beta_3/2))/
                                      (abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta10)
z_Beta10=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10/kappa+p_Reference
       *(1-p_Reference)/n_Beta10)
(Power_Beta10=2*(pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))-1)

TwoSampleUnpairedDesign.Equivalence <- as.data.frame(cbind(epsilon,n_Beta30,n_Beta20,n_Beta10))
names(TwoSampleUnpairedDesign.Equivalence) <- c("Cure.Rate.Change",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
TwoSampleUnpairedDesign.Equivalence.Reshaped <- gather(TwoSampleUnpairedDesign.Equivalence,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
TwoSampleUnpairedDesign.Equivalence.Reshaped$Label <- rep("TSUD_EQUIVALENCE",nrow(TwoSampleUnpairedDesign.Equivalence.Reshaped))

TwoSampleUnpairedDesign.Equivalence.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(TwoSampleUnpairedDesign.Equivalence.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.Equivalence.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("Two-Sample Unpaired Design : Test for Equivalence"))

```

###  1.2.5 Evaluation Summary
|
| Sample computation and power analysis comparison:
|
| **[A]** The minimum sample size required for the treatment group in a Two-Sample Unpaired Design study is dependent upon the following factors defined and hypothesized prior to the clinical research:
|      **[A.1]** Study Hypothesis (Equality, Non-Inferiority, Superiority, Equivalence)
|      **[A.2]** Level of significance (Alpha) : Lower value increases sample size
|      **[A.3]** Power of the test (Beta) : Higher value increases sample size
|      **[A.5]** Epsilon (Difference between Treatment Response Rate and Control Response Rate) : Lower value increases sample size
|      **[A.6]** Delta (Testing margin, as applicable) : Higher value increases sample size
| **[B]** Given the level of significance = 5%, control response rate = 65% and treatment response rate = 85% to 95% representing epsilon values = 20% to 30%, the range of sample sizes is given on the respective power analyses provided for each study hypotheses -
|      **[B.1]** OSD_EQUALITY : 
|             **[B.1.1]** For 70% power, sample size = 19 to 55 
|             **[B.1.2]** For 80% power, sample size = 24 to 70 
|             **[B.1.3]** For 90% power, sample size = 33 to 94 
|      **[B.2]** OSD_NONINFERIORITY with Delta = -10% : 
|             **[B.2.1]** For 70% power, sample size = 9 to 19 
|             **[B.2.2]** For 80% power, sample size = 11 to 25 
|             **[B.2.3]** For 90% power, sample size = 15 to 34 
|      **[B.3]** OSD_SUPERIORITY with Delta = +2% :  
|             **[B.3.1]** For 70% power, sample size = 17 to 52 
|             **[B.3.2]** For 80% power, sample size = 22 to 68 
|             **[B.3.3]** For 90% power, sample size = 31 to 94 
|      **[B.4]** OSD_EQUIVALENCE with Delta = +2% : 
|             **[B.4.1]** For 70% power, sample size = 26 to 79 
|             **[B.4.2]** For 80% power, sample size = 31 to 94 
|             **[B.4.3]** For 90% power, sample size = 38 to 119 
|
```{r section_1.2.5, warning=FALSE, message=FALSE}

TSUD_EQUALITY.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.Equality.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

TSUD_NONINFERIORITY.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.NonInferiority.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

TSUD_SUPERIORITY.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.Superiority.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

TSUD_EQUIVALENCE.PowerAnalysis <- ggplot(TwoSampleUnpairedDesign.Equivalence.Reshaped,
                                                      aes(x=Cure.Rate.Change,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Cure Rate Change",
                      limits=c(0.2,0.3),
                      breaks=seq(0.2,0.3,by=0.02)) +
  scale_y_continuous(name="Sample Size Per Group",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

TSUD_PowerAnalysis <- ggarrange(TSUD_EQUALITY.PowerAnalysis,
                               TSUD_NONINFERIORITY.PowerAnalysis,
                               TSUD_SUPERIORITY.PowerAnalysis,
                               TSUD_EQUIVALENCE.PowerAnalysis,
                               ncol=2, nrow=2)

annotate_figure(TSUD_PowerAnalysis,
                top = text_grob("Two-Sample Unpaired Design Power Analysis by Statistical Hypothesis",
                                color = "black",
                                face = "bold",
                                size = 14))


```

|
##  1.3 Two-Sample Paired Design (TSPD)
|
| [Two-Sample Paired Design](https://www.taylorfrancis.com/books/mono/10.1201/9781315183084/sample-size-calculations-clinical-research-shein-chung-chow-jun-shao-hansheng-wang-yuliya-lokhnygina) involves individual proportions from sampled paired subjects between treatment and control groups. In clinical research, it is often of interest to examine any change in laboratory values before and after the application of the treatment. When the response variable is categorical, this type of change is called a categorical shift. Parameters needed for the computations are as follows:
|
| **[A]** <span style="color: #FF0000">P_01</span> : Categorical shift shift from 0 (normal) in pre-treatment to 1 (abnormal) in post-treatment
|
| **[B]** <span style="color: #FF0000">P10</span> : Categorical shift shift from 1 (abnormal) in pre-treatment to 0 (normal) in post-treatment
|
| **[D]** <span style="color: #FF0000">Alpha</span> : Maximum allowed Type I error
|
| **[E]** <span style="color: #FF0000">Beta</span> : Maximum allowed Type II error
|
| A case scenario was provided as follows to demonstrate sample size computation and power analysis as applied for this type of hypothesis:
|
| **[Case Scenario]** A clinical research study is being pursued concerning a test compound under in terms of the proportions of the patients with nocturnal hypoglycaemia, which is defined to be the patients with the overnight glucose value ≤ 3.5 mgL on two consecutive visits (15 minutes/per visit). At the first visit (pre-treatment), patients’ overnight glucose levels will be measured every 15 minutes. Whether or not the patient experiences nocturnal hypoglycaemia will be recorded. At the second visit, patients will receive the study compound and the overnight glucose levels will be obtained in a similar manner. Patients’ experience on nocturnal hypoglycaemia will also be recorded.
|
###  1.3.1 Test for Categorical Shift (TSPD_CATEGORICALSHIFT)
|
| **[Research Question]** According to some pilot studies, it is expected that about 40 to 60% (P_10 = 0.50 to 0.60 with increment = 0.02 ) of patients will shift from 1 (nocturnal hypoglycaemia pre-treatment) to 0 (normal post-treatment) and 20% (P_01 = 0.20) of patients will shift from 0 (normal pre-treatment) to 1 (nocturnal hypoglycaemia post-treatment). Given a level of significance of 0.05, evaluate the sample size range for a test of categorical shift to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** P_01 (Categorical shift from normal in pre-treatment to hypoglycaemia in post-treatment) - P_10 (Categorical shift from hypoglycaemia in pre-treatment to normal in post-treatment) equals 0
|
| **[Alternative Hypothesis]** P_01 (Categorical shift from normal in pre-treatment to hypoglycaemia in post-treatment) - P_10 (Categorical shift from hypoglycaemia in pre-treatment to normal in post-treatment) does not equal 0
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies a significant shift between   between the hypoglycaemia and normal categories before and after treatment
|
| **[A]** <span style="color: #FF0000">P_10</span> : 50 to 60% at 2% intervals
|
| **[B]** <span style="color: #FF0000">P_01</span> : 20%
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
```{r section_1.3.1, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for P10
##################################
p_10=seq(0.50,0.60,0.02)

##################################
# Defining a fixed hypothesized value for P01
##################################
p_01=0.20

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Computing the categorical shifts
##################################
p_Disc=p_10 + p_01
p_Diff=p_10 - p_01

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=((qnorm(1-alpha/2)*sqrt(p_Disc)+qnorm(1-beta_1)*sqrt(p_Disc-p_Diff^2))/p_Diff)^2)
ceiling(n_Beta30)
x1_Beta30=( p_Diff*sqrt(n_Beta30)-qnorm(1-alpha/2)*sqrt(p_Disc))/sqrt(p_Disc-p_Diff^2)
x2_Beta30=(-p_Diff*sqrt(n_Beta30)-qnorm(1-alpha/2)*sqrt(p_Disc))/sqrt(p_Disc-p_Diff^2)
(Power_Beta30 = pnorm(x1_Beta30)+pnorm(x2_Beta30))

beta_2=beta[2]
(n_Beta20=((qnorm(1-alpha/2)*sqrt(p_Disc)+qnorm(1-beta_2)*sqrt(p_Disc-p_Diff^2))/p_Diff)^2)
ceiling(n_Beta20)
x1_Beta20=( p_Diff*sqrt(n_Beta20)-qnorm(1-alpha/2)*sqrt(p_Disc))/sqrt(p_Disc-p_Diff^2)
x2_Beta20=(-p_Diff*sqrt(n_Beta20)-qnorm(1-alpha/2)*sqrt(p_Disc))/sqrt(p_Disc-p_Diff^2)
(Power_Beta20 = pnorm(x1_Beta20)+pnorm(x2_Beta20))


beta_3=beta[3]
(n_Beta10=((qnorm(1-alpha/2)*sqrt(p_Disc)+qnorm(1-beta_3)*sqrt(p_Disc-p_Diff^2))/p_Diff)^2)
ceiling(n_Beta10)
x1_Beta10=( p_Diff*sqrt(n_Beta10)-qnorm(1-alpha/2)*sqrt(p_Disc))/sqrt(p_Disc-p_Diff^2)
x2_Beta10=(-p_Diff*sqrt(n_Beta10)-qnorm(1-alpha/2)*sqrt(p_Disc))/sqrt(p_Disc-p_Diff^2)
(Power_Beta10 = pnorm(x1_Beta10)+pnorm(x2_Beta10))

TwoSamplePairedDesign.CategoricalShift <- as.data.frame(cbind(p_01,p_10,n_Beta30,n_Beta20,n_Beta10))
names(TwoSamplePairedDesign.CategoricalShift) <- c("Categorical.Shift.P01",
                                                   "Categorical.Shift.P10",
                                                   "Power=70%",
                                                   "Power=80%",
                                                   "Power=90%")

##################################
# Restructuring the data
##################################
TwoSamplePairedDesign.CategoricalShift.Reshaped <- gather(TwoSamplePairedDesign.CategoricalShift,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
TwoSamplePairedDesign.CategoricalShift.Reshaped$Label <- rep("TSPD_CATEGORICALSHIFT",nrow(TwoSamplePairedDesign.CategoricalShift.Reshaped))

TwoSamplePairedDesign.CategoricalShift.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(TwoSamplePairedDesign.CategoricalShift.PowerAnalysis <- ggplot(TwoSamplePairedDesign.CategoricalShift.Reshaped,
                                                      aes(x=Categorical.Shift.P10,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Categorical Shift (Hypoglycaemia to Normal)",
                      limits=c(0.5,0.6),
                      breaks=seq(0.5,0.6,by=0.02)) +
  scale_y_continuous(name="Sample Size for Both Groups",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("Two-Sample Paired Design : Test for Categorical Shift"))

```

###  1.3.2 Evaluation Summary
|
| Sample computation and power analysis comparison:
|
| **[A]** The minimum sample size required for both groups in a Two-Sample Paired Design study to evaluate categorixcal shift is dependent upon the following factors defined and hypothesized prior to the clinical research:
|      **[A.1]** Level of significance (Alpha) : Lower value increases sample size
|      **[A.2]** Power of the test (Beta) : Higher value increases sample size
|      **[A.3]** Categorical Shift (Difference between P_10 and P_01) : Lower value increases sample size
| **[B]** Given the level of significance = 5%, P_01 = 20% and P_10 = 50% to 60%, the range of sample sizes is given on the respective power analyses provided for each study hypotheses -
|      **[B.1]** TSPD_CATEGORICALSHIFT : 
|             **[B.1.1]** For 70% power, sample size = 30 to 47 
|             **[B.1.2]** For 80% power, sample size = 37 to 59 
|             **[B.1.3]** For 90% power, sample size = 49 to 78 
|
```{r section_1.3.2, warning=FALSE, message=FALSE}

TSPD_CATEGORICALSHIFT.PowerAnalysis <- ggplot(TwoSamplePairedDesign.CategoricalShift.Reshaped,
                                                      aes(x=Categorical.Shift.P10,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   facet_grid(. ~ Label) +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Categorical Shift (Hypoglycaemia to Normal)",
                      limits=c(0.5,0.6),
                      breaks=seq(0.5,0.6,by=0.02)) +
  scale_y_continuous(name="Sample Size for Both Groups",
                     limits=c(0,120),
                     breaks=seq(0,120,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

TSPD_PowerAnalysis <- ggarrange(TSPD_CATEGORICALSHIFT.PowerAnalysis,
                               ncol=1, nrow=1)

annotate_figure(TSPD_PowerAnalysis,
                top = text_grob("Two-Sample Paired Design Power Analysis by Statistical Hypothesis",
                                color = "black",
                                face = "bold",
                                size = 14))


```

##  1.4 Multiple-Sample Design One-Way ANOVA Pairwise (MSDOWAP)
|
###  1.4.1 Test for Equality (MSDOWAP_EQUALITY)
|
```{r section_1.4.1, warning=FALSE, message=FALSE}

```

# **2. References**
|
| **[Book]** [Sample Size Calculations in Clinical Research](https://www.taylorfrancis.com/books/mono/10.1201/9781315183084/sample-size-calculations-clinical-research-shein-chung-chow-jun-shao-hansheng-wang-yuliya-lokhnygina) by Shein-Chung Chow, Jun Shao, Hansheng Wang and Yuliya Lokhnygina
| **[Book]** [Clinical Trial Data Analysis Using R and SAS](https://www.taylorfrancis.com/books/mono/10.1201/9781315155104/clinical-trial-data-analysis-using-sas-ding-geng-din-chen-karl-peace-pinggao-zhang) by Ding-Geng Chen, Karl Peace and Pinggao Zhang
| **[Book]** [Design and Analysis of Experiments with R](https://www.taylorfrancis.com/books/mono/10.1201/b17883/design-analysis-experiments-john-lawson) by John Lawson
| **[Book]** [Design and Analysis of Experiments](https://link.springer.com/book/10.1007/978-3-319-52250-0) by Angela Dean , Daniel Voss and Danel Draguljić
| **[Book]** [Design and Analysis of Experiments](https://bcs.wiley.com/he-bcs/Books?action=index&bcsId=10790&itemId=1119320933) by Douglas Montgomery
| **[R Package]** [rstatix](https://mran.microsoft.com/web/packages/rstatix/index.html) by Alboukadel Kassambara
| **[R Package]** [car](https://cran.r-project.org/web/packages/car/vignettes/embedding.pdf) by John Fox and Sanford Weisberg
| **[R Package]** [effects](https://cran.r-project.org/web/packages/effects/vignettes/methods-supported-by-effects.pdf) by John Fox and Sanford Weisberg
| **[R Package]** [multcomp](https://cran.r-project.org/web/packages/multcomp/vignettes/generalsiminf.pdf) by Torsten Hothorn, Frank Bretz and Peter Westfall
| **[R Package]** [psych](http://personality-project.org/r/overview.pdf) by William Revelle
| **[R Package]** [bootstrap](https://cran.r-project.org/web/packages/bootstrap/bootstrap.pdf) by Robert Tibshirani
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick Novomestky
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html) by Hadley Wickham
| **[R Package]** [ggplot2](https://cran.r-project.org/web/packages/ggplot2/) by Hadley Wickham
| **[R Package]** [ggpubr](https://cran.r-project.org/web/packages/ggpubr/index.html) by Alboukadel Kassambara
| **[R Package]** [ggfortify](https://cran.r-project.org/web/packages/ggfortify/index.html) by Yuan Tang
| **[R Package]** [trend](https://cran.r-project.org/web/packages/trend/index.html) by Thorsten Pohlert
| **[Article]** [Power and Sample Size](https://powerandsamplesize.com/) by HyLown Consulting Team
| **[Article]** [An Introduction to Different Types of Study Design](https://s4be.cochrane.org/blog/2021/04/06/an-introduction-to-different-types-of-study-design/) by Hadi Abbas
| **[Article]** [Case-Control and Cohort Studies: A Brief Overview](https://s4be.cochrane.org/blog/2017/12/06/case-control-and-cohort-studies-overview/) by Saul Crandon
| **[Article]** [Cohort Studies: Prospective and Retrospective Designs](https://s4be.cochrane.org/blog/2019/03/06/cohort-studies-prospective-retrospective-designs/) by Izabel de Oliveira
| **[Article]** [Prevalence vs. Incidence: What is the Difference](https://s4be.cochrane.org/blog/2020/11/06/prevalence-vs-incidence-what-is-the-difference/) by Georgina Ford
| **[Article]** [Randomized Clinical Trial (RCT): Simple Definition, Phases, and Types](https://www.statisticshowto.com/experimental-design/randomized-clinical-trial-rcts/) by Statistics-How-To Team
|
|
|
|