---
title: 'R : Sample Size and Power Calculations for Tests Comparing Proportions in Clinical Research'
author: "John Pauline Pineda"
date: "May 21, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```

# **1. Table of Contents**
|
| This document presents a non-exhaustive list of sample size and power calculations for clinical research proportion comparison tests using various helpful packages in <mark style="background-color: #CCECFF">**R**</mark>.
|
| Proportion comparison tests applied during clinical research refer to trials evaluated in terms of discrete clinical endpoints. The objectives of the intended clinical trials usually include the evaluation of clinical response (including complete response, partial response, and stable disease), survival in cancer trials, and the presence of adverse events in clinical trials. The equations applied in this study (mostly contained from the book  <mark style="background-color: #CCECFF">**Sample Size Calculations in Clinical Research**</mark> and implemented using the <mark style="background-color: #CCECFF">**base**</mark> package) attempt to provide calculations for the sample size and statistical power based on the study objectives and hypotheses of interest. 
|
##  1.1 One-Sample Design (OSD)
|
| [One-Sample Design](https://www.taylorfrancis.com/books/mono/10.1201/9781315183084/sample-size-calculations-clinical-research-shein-chung-chow-jun-shao-hansheng-wang-yuliya-lokhnygina) involves individual binary response classes from sampled subjects. In clinical research, classes could be the binary indicator of the responsiveness to the intervention applied within a treatment group. Responses are assumed to be independent and identically distributed normal random variables with proportion equal to the true response rate. Parameters needed for the computations are as follows:
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : True response rate obtained from sampled subjects 
|
| **[B]** <span style="color: #FF0000">Reference</span> : Baseline value for comparison
|
| **[C]** <span style="color: #FF0000">Alpha</span> : Maximum allowed Type I error
|
| **[D]** <span style="color: #FF0000">Beta</span> : Maximum allowed Type II error
|
| **[E]** <span style="color: #FF0000">Delta</span> : 
|      **[E.1]** Minimum testing margin to establish that the true response rate is much better than reference
|      **[E.2]** Minimum testing margin to establish that the true response rate is not much worse as the reference
|      **[E.3]** Minimum testing margin to establish that the true response rate is no better and no worse than the reference
|
| A case scenario was provided as follows to demonstrate sample size computation and power analysis as applied on different types of hypotheses:
|
| **[Case Scenario]** A clinical research study is being pursued concerning osteoporosis in post-menopausal women. Osteoporosis and osteopenia (or decreased bone mass) most commonly develop in post-menopausal women. The consequences of osteoporosis are vertebral crush fractures and hip fractures. It is of interest to evaluate the treatment effect in terms of the response rate at the end of the study. A subject may be defined as a responder if there is an improvement in bone density by more than one standard deviation (SD) or 30% of the measurements of bone density.
|
###  1.1.1 Test for Equality (OSD_EQUALITY)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For prevention of progression from osteopenia to osteoporosis, the study aims to demonstrate that the true response rate post-treatment and a reference rate of 15% are different. Given a level of significance of 0.05, evaluate the sample size range for a test of equality to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Post-treatment true response rate - Reference response rate equals 0
|
| **[Alternative Hypothesis]** Post-treatment mean bone density - Reference response rate does not equal 0
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies difference between the true response rate post-treatment and reference rate
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : 0 testing margin for the Test of Equality hypothesis
|
```{r section_1.1.1, warning=FALSE, message=FALSE}

##################################
# Loading R libraries
##################################
library(moments)
library(car)
library(multcomp)
library(effects)
library(psych)
library(ggplot2)
library(dplyr)
library(ggpubr)
library(rstatix)
library(ggfortify)
library(trend)

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha/2)+qnorm(1-beta_1))/(p_ResponseRate-p_Reference))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha/2))+pnorm(-z_Beta30-qnorm(1-alpha/2)))

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha/2)+qnorm(1-beta_2))/(p_ResponseRate-p_Reference))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha/2))+pnorm(-z_Beta20-qnorm(1-alpha/2)))

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha/2)+qnorm(1-beta_3))/(p_ResponseRate-p_Reference))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha/2))+pnorm(-z_Beta10-qnorm(1-alpha/2)))

OneSampleDesign.Equality <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.Equality) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.Equality.Reshaped <- gather(OneSampleDesign.Equality,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.Equality.Reshaped$Label <- rep("OSD_EQUALITY",nrow(OneSampleDesign.Equality.Reshaped))

OneSampleDesign.Equality.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.Equality.PowerAnalysis <- ggplot(OneSampleDesign.Equality.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Equality"))

```

###  1.1.2 Test for Non-Inferiority (OSD_NONINFERIORITY)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For prevention of progression from osteopenia to osteoporosis, the study aims to demonstrate that the true response rate post-treatment is not much worse than the reference rate of 15% by a clinically meaningful difference equal to −5%. Given a level of significance of 0.05, evaluate the sample size range for a test of non-inferiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Post-treatment true response rate - Reference response rate <= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Post-treatment mean bone density - Reference response rate > Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies non-inferiority of the true response rate post-treatment as compared to the reference rate, given the delta
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : -5% testing margin for the Test of Non-Inferiority hypothesis
|
```{r section_1.1.2, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the non-inferiority delta
##################################
delta=-0.05

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_1))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_2))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_3))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))

OneSampleDesign.NonInferiority <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.NonInferiority) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.NonInferiority.Reshaped <- gather(OneSampleDesign.NonInferiority,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.NonInferiority.Reshaped$Label <- rep("OSD_NONINFERIORITY",nrow(OneSampleDesign.NonInferiority.Reshaped))

OneSampleDesign.NonInferiority.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.NonInferiority.PowerAnalysis <- ggplot(OneSampleDesign.NonInferiority.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Non-Inferiority"))

```

###  1.1.3 Test for Superiority (OSD_SUPERIORITY)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For prevention of progression from osteopenia to osteoporosis, the study aims to demonstrate that the true response rate post-treatment is much better than the reference rate of 15% by a clinically meaningful difference equal to +20%. Given a level of significance of 0.05, evaluate the sample size range for a test of superiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Post-treatment true response rate - Reference response rate <= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Post-treatment mean bone density - Reference response rate > Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies superiority of the true response rate post-treatment as compared to the reference rate, given the delta
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : +20% testing margin for the Test of Superiority hypothesis
|
```{r section_1.1.3, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the Superiority delta
##################################
delta=0.05

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_1))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta30)
z_Beta30=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_2))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta20)
z_Beta20=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_3))/(p_ResponseRate-p_Reference-delta))^2)
ceiling(n_Beta10)
z_Beta10=(p_ResponseRate-p_Reference-delta)/sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))

OneSampleDesign.Superiority <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.Superiority) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.Superiority.Reshaped <- gather(OneSampleDesign.Superiority,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.Superiority.Reshaped$Label <- rep("OSD_SUPERIORITY",nrow(OneSampleDesign.Superiority.Reshaped))

OneSampleDesign.Superiority.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.Superiority.PowerAnalysis <- ggplot(OneSampleDesign.Superiority.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Superiority"))

```

###  1.1.4 Test for Equivalence (OSD_EQUIVALENCE)
|
| **[Research Question]** Suppose that the response rate of the patient population under study after treatment is expected to be range from 40% to 60% with increments of 10%. For a special investigation, the study aims to demonstrate that the true response rate post-treatment is not much worse or better than the reference rate of 15% by a clinically meaningful difference equal to 10%. Given a level of significance of 0.05, evaluate the sample size range for a test of superiority to achieve statistical test powers equal to 70%, 80% and 90%.
|
| **[Null Hypothesis]** Absolute value of (Post-treatment true response rate - Reference response rate) >= Clinically meaningful difference
|
| **[Alternative Hypothesis]** Absolute value of (Post-treatment true response rate - Reference response rate) < Clinically meaningful difference
|
| **[Hypothesis Test]** Rejection of the null hypothesis implies equivalence of the true response rate post-treatment as compared to the reference rate, given the delta
|
| **[A]** <span style="color: #FF0000">True Response Rate</span> : 0.40 to 0.60 at 0.10 intervals 
|
| **[B]** <span style="color: #FF0000">Reference</span> : 0.15
|
| **[C]** <span style="color: #FF0000">Alpha</span> : 0.05
|
| **[D]** <span style="color: #FF0000">Beta</span> : 0.30, 0.20 and 0.10 corresponding to 70%, 80% and 90% statistical powers
|
| **[F]** <span style="color: #FF0000">Delta</span> : +10% testing margin for the Test of Equivalence hypothesis
|
```{r section_1.1.4, warning=FALSE, message=FALSE}

##################################
# Defining a range of possible hypothesized values for p_ResponseRate
##################################
p_ResponseRate=seq(0.4,0.6,0.05)

##################################
# Defining a fixed hypothesized value for p_Reference
##################################
p_Reference=0.15

##################################
# Defining a fixed hypothesized value for the Type I error
##################################
alpha=0.05

##################################
# Defining a range of possible hypothesized values for the Type II error
##################################
beta=c(0.30,0.20,0.10)

##################################
# Defining the Equivalence delta
##################################
delta=0.05

##################################
# Computing the range of samples sizes based on different levels of Type II errors
##################################
beta_1=beta[1]
(n_Beta30=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_1/2))/(abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta30)
z_Beta30=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta30)
(Power_Beta30=2*(pnorm(z_Beta30-qnorm(1-alpha))+pnorm(-z_Beta30-qnorm(1-alpha)))-1)

beta_2=beta[2]
(n_Beta20=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_2/2))/(abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta20)
z_Beta20=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta20)
(Power_Beta20=2*(pnorm(z_Beta20-qnorm(1-alpha))+pnorm(-z_Beta20-qnorm(1-alpha)))-1)

beta_3=beta[3]
(n_Beta10=p_ResponseRate*(1-p_ResponseRate)*
    ((qnorm(1-alpha)+qnorm(1-beta_3/2))/(abs(p_ResponseRate-p_Reference)-delta))^2)
ceiling(n_Beta10)
z_Beta10=(abs(p_ResponseRate-p_Reference)-delta)/
  sqrt(p_ResponseRate*(1-p_ResponseRate)/n_Beta10)
(Power_Beta10=2*(pnorm(z_Beta10-qnorm(1-alpha))+pnorm(-z_Beta10-qnorm(1-alpha)))-1)

OneSampleDesign.Equivalence <- as.data.frame(cbind(p_ResponseRate,n_Beta30,n_Beta20,n_Beta10))
names(OneSampleDesign.Equivalence) <- c("Posttreatment.True.Response.Rate",
                                 "Power=70%",
                                 "Power=80%",
                                 "Power=90%")

##################################
# Restructuring the data
##################################
OneSampleDesign.Equivalence.Reshaped <- gather(OneSampleDesign.Equivalence,
                                            "Power=70%","Power=80%","Power=90%",
                                            key="Power",
                                            value="Sample.Size")
OneSampleDesign.Equivalence.Reshaped$Label <- rep("OSD_EQUIVALENCE",nrow(OneSampleDesign.Equivalence.Reshaped))

OneSampleDesign.Equivalence.Reshaped

##################################
# Plotting the sample sizes and power curves
##################################
(OneSampleDesign.Equivalence.PowerAnalysis <- ggplot(OneSampleDesign.Equivalence.Reshaped,
                                                      aes(x=Posttreatment.True.Response.Rate,
                                                          y=Sample.Size, 
                                                          color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) +
  ggtitle("One-Sample Design : Test for Equivalence"))

```

###  1.1.5 Evaluation Summary
|
| Sample computation and power analysis comparison:
|
| **[A]** The minimum sample size required for the treatment group in a One-Sample Design study is dependent upon the following factors defined and hypothesized prior to the clinical research:
|      **[A.1]** Study Hypothesis (Equality, Non-Inferiority, Superiority, Equivalence)
|      **[A.2]** Level of significance (Alpha) : Lower value increases sample size
|      **[A.3]** Power of the test (Beta) : Higher value increases sample size
|      **[A.5]** Epsilon (Difference between True Response Rate and Reference Rate) : Lower value increases sample size
|      **[A.6]** Delta (Testing margin, as applicable) : Higher value increases sample size
| **[B]** Given the level of significance = 5%, reference rate = 15%, true response rate after treatment = 40% to 60% representing epsilon values = 25% to 45%, the range of sample sizes is given on the respective power analyses provided for each study hypotheses -
|      **[B.1]** OSD_EQUALITY : 
|             **[B.1.1]** For 70% power, sample size = 8 to 24 
|             **[B.1.2]** For 80% power, sample size = 10 to 31 
|             **[B.1.3]** For 90% power, sample size = 13 to 41 
|      **[B.2]** OSD_NONINFERIORITY with Delta = -5% : 
|             **[B.2.1]** For 70% power, sample size = 5 to 13 
|             **[B.2.2]** For 80% power, sample size = 6 to 17 
|             **[B.2.3]** For 90% power, sample size = 9 to 23 
|      **[B.3]** OSD_SUPERIORITY with Delta = +20% :  
|             **[B.3.1]** For 70% power, sample size = 8 to 29 
|             **[B.3.2]** For 80% power, sample size = 10 to 38 
|             **[B.3.3]** For 90% power, sample size = 13 to 52 
|      **[B.4]** OSD_EQUIVALENCE with Delta = +10% : 
|             **[B.4.1]** For 70% power, sample size = 11 to 44 
|             **[B.4.2]** For 80% power, sample size = 13 to 52 
|             **[B.4.3]** For 90% power, sample size = 17 to 65 
|
```{r section_1.1.5, warning=FALSE, message=FALSE}
##################################
# Consolidating the power analyses charts
##################################

OSD_EQUALITY.PowerAnalysis <- ggplot(OneSampleDesign.Equality.Reshaped,
                                     aes(x=Posttreatment.True.Response.Rate,
                                         y=Sample.Size,
                                         color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50)) 

OSD_NONINFERIORITY.PowerAnalysis <- ggplot(OneSampleDesign.NonInferiority.Reshaped,
                                           aes(x=Posttreatment.True.Response.Rate,
                                               y=Sample.Size, 
                                               color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

OSD_SUPERIORITY.PowerAnalysis <- ggplot(OneSampleDesign.Superiority.Reshaped,
                                        aes(x=Posttreatment.True.Response.Rate,
                                            y=Sample.Size, 
                                            color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))

OSD_EQUIVALENCE.PowerAnalysis <- ggplot(OneSampleDesign.Equivalence.Reshaped,
                                        aes(x=Posttreatment.True.Response.Rate,
                                            y=Sample.Size,
                                            color=Power)) +
   geom_line(size=1)+
   geom_point(size=4)+
   theme_bw() +
   scale_color_brewer(palette="Paired") +
   scale_x_continuous(name="Hypothesized Post-Treatment True Response Rate",
                      limits=c(0.40,0.60),
                      breaks=seq(0.40,0.60,
                                 by=0.05)) +
  scale_y_continuous(name="Treatment Group Sample Size",
                     limits=c(0,100),
                     breaks=seq(0,100,by=10)) +
  theme(axis.title.x=element_text(color="black",face="bold",size=12),
        legend.position="top",
        axis.title.y=element_text(color="black",face="bold",size=12),
        plot.title=element_text(color="black",size=14,face="bold",hjust=0.50))


OSD_PowerAnalysis <- ggarrange(OSD_EQUALITY.PowerAnalysis,
                               OSD_NONINFERIORITY.PowerAnalysis,
                               OSD_SUPERIORITY.PowerAnalysis,
                               OSD_EQUIVALENCE.PowerAnalysis,
                               ncol=2, nrow=2)

annotate_figure(OSD_PowerAnalysis,
                top = text_grob("One-Sample Design Power Analysis by Statistical Hypothesis",
                                color = "black",
                                face = "bold",
                                size = 14))

```

|
##  1.2 Two-Sample Unpaired Design (TSUD)
|
###  1.2.1 Test for Equality (TSUD_EQUALITY)
|
```{r section_1.2.1, warning=FALSE, message=FALSE}

```

###  1.2.2 Test for Non-Inferiority (TSUD_NONINFERIORITY)
|
```{r section_1.2.2, warning=FALSE, message=FALSE}

```

###  1.2.3 Test for Superiority (TSUD_SUPERIORITY)
|
```{r section_1.2.3, warning=FALSE, message=FALSE}

```

###  1.2.4 Test for Equivalence (TSUD_EQUIVALENCE)
|
```{r section_1.2.4, warning=FALSE, message=FALSE}

```

###  1.2.5 Evaluation Summary
|
```{r section_1.2.5, warning=FALSE, message=FALSE}

```
|
##  1.3 Two-Sample Paired Design (TSPD)
|
###  1.3.1 Test for Equality (TSPD_EQUALITY)
|
```{r section_1.3.1, warning=FALSE, message=FALSE}

```
|
##  1.4 Multiple-Sample Design One-Way ANOVA Pairwise (MSDOWAP)
|
###  1.4.1 Test for Equality (MSDOWAP_EQUALITY)
|
```{r section_1.4.1, warning=FALSE, message=FALSE}

```

# **2. References**
|
| **[Book]** [Sample Size Calculations in Clinical Research](https://www.taylorfrancis.com/books/mono/10.1201/9781315183084/sample-size-calculations-clinical-research-shein-chung-chow-jun-shao-hansheng-wang-yuliya-lokhnygina) by Shein-Chung Chow, Jun Shao, Hansheng Wang and Yuliya Lokhnygina
| **[Book]** [Clinical Trial Data Analysis Using R and SAS](https://www.taylorfrancis.com/books/mono/10.1201/9781315155104/clinical-trial-data-analysis-using-sas-ding-geng-din-chen-karl-peace-pinggao-zhang) by Ding-Geng Chen, Karl Peace and Pinggao Zhang
| **[Book]** [Design and Analysis of Experiments with R](https://www.taylorfrancis.com/books/mono/10.1201/b17883/design-analysis-experiments-john-lawson) by John Lawson
| **[Book]** [Design and Analysis of Experiments](https://link.springer.com/book/10.1007/978-3-319-52250-0) by Angela Dean , Daniel Voss and Danel Draguljić
| **[Book]** [Design and Analysis of Experiments](https://bcs.wiley.com/he-bcs/Books?action=index&bcsId=10790&itemId=1119320933) by Douglas Montgomery
| **[R Package]** [rstatix](https://mran.microsoft.com/web/packages/rstatix/index.html) by Alboukadel Kassambara
| **[R Package]** [car](https://cran.r-project.org/web/packages/car/vignettes/embedding.pdf) by John Fox and Sanford Weisberg
| **[R Package]** [effects](https://cran.r-project.org/web/packages/effects/vignettes/methods-supported-by-effects.pdf) by John Fox and Sanford Weisberg
| **[R Package]** [multcomp](https://cran.r-project.org/web/packages/multcomp/vignettes/generalsiminf.pdf) by Torsten Hothorn, Frank Bretz and Peter Westfall
| **[R Package]** [psych](http://personality-project.org/r/overview.pdf) by William Revelle
| **[R Package]** [bootstrap](https://cran.r-project.org/web/packages/bootstrap/bootstrap.pdf) by Robert Tibshirani
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick Novomestky
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html) by Hadley Wickham
| **[R Package]** [ggplot2](https://cran.r-project.org/web/packages/ggplot2/) by Hadley Wickham
| **[R Package]** [ggpubr](https://cran.r-project.org/web/packages/ggpubr/index.html) by Alboukadel Kassambara
| **[R Package]** [ggfortify](https://cran.r-project.org/web/packages/ggfortify/index.html) by Yuan Tang
| **[R Package]** [trend](https://cran.r-project.org/web/packages/trend/index.html) by Thorsten Pohlert
| **[Article]** [Power and Sample Size](https://powerandsamplesize.com/) by HyLown Consulting Team
| **[Article]** [An Introduction to Different Types of Study Design](https://s4be.cochrane.org/blog/2021/04/06/an-introduction-to-different-types-of-study-design/) by Hadi Abbas
| **[Article]** [Case-Control and Cohort Studies: A Brief Overview](https://s4be.cochrane.org/blog/2017/12/06/case-control-and-cohort-studies-overview/) by Saul Crandon
| **[Article]** [Cohort Studies: Prospective and Retrospective Designs](https://s4be.cochrane.org/blog/2019/03/06/cohort-studies-prospective-retrospective-designs/) by Izabel de Oliveira
| **[Article]** [Prevalence vs. Incidence: What is the Difference](https://s4be.cochrane.org/blog/2020/11/06/prevalence-vs-incidence-what-is-the-difference/) by Georgina Ford
| **[Article]** [Randomized Clinical Trial (RCT): Simple Definition, Phases, and Types](https://www.statisticshowto.com/experimental-design/randomized-clinical-trial-rcts/) by Statistics-How-To Team
|
|
|
|